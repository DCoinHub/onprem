{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from onprem.core import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Built-In Web App\n",
    "\n",
    "**OnPrem.LLM** includes a built-in Web app to access the LLM. \n",
    "\n",
    "To start it, run the following command after installation:\n",
    "\n",
    "```shell\n",
    "onprem --port 8000\n",
    "```\n",
    "Then, enter `localhost:8000` (or `<domain_name>:8000` if running on remote server) in your Web browser to access the application:\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/amaiya/onprem/master/onprem_screenshot.png\" border=\"1\" alt=\"screenshot\" width=\"600\"/>\n",
    "\n",
    "More information on the `onprem` command:\n",
    "```sh\n",
    "$:~/projects/github/onprem$ onprem --help\n",
    "usage: onprem [-h] [-p PORT] [-a ADDRESS] [-v]\n",
    "\n",
    "Start the streamlit app\n",
    "Example: onprem --port 8000\n",
    "\n",
    "optional arguments:\n",
    "  -h, --help            show this help message and exit\n",
    "  -p PORT, --port PORT  Port to use; default is 8501\n",
    "  -a ADDRESS, --address ADDRESS\n",
    "                        Address to bind; default is 0.0.0.0\n",
    "  -v, --version         Print app version\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The app requires a file called `ui.yml` exists in the `onprem_data` folder in the user's home directory. This file stores information used by the Web app such as the model to use. An example `ui.yml` is [here](https://github.com/amaiya/onprem/blob/master/nbs/ui.yml) and is also shown below:\n",
    "\n",
    "```yaml\n",
    "llm:\n",
    "  # model url or name (model should already have been downloaed)\n",
    "  model_url:  wizardlm-13b-v1.2.ggmlv3.q4_0.bin\n",
    "  # number of layers offloaded to GPU\n",
    "  n_gpu_layers: 32\n",
    "  # path to vector db folder\n",
    "  vectordb_path: /home/your_user_name/onprem_data/vectordb\n",
    "  # path to model download folder\n",
    "  model_download_path: /home/your_user_name/onprem_data\n",
    "prompt:\n",
    "  # text to append to end of prompt\n",
    "  append_'to_prompt: Do not answer if there is no mention of this in context.\n",
    "streamlit:\n",
    "  # title of application\n",
    "  title: OnPrem.LLM\n",
    "```\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
